{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_H0nK5355mmx"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0AqK8QX5_Ei"
      },
      "outputs": [],
      "source": [
        "data_dir = Path(\"data/\")\n",
        "assert data_dir.exists(), \"Expected /data to be present\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u3MHy9a0uC9-"
      },
      "outputs": [],
      "source": [
        "# Load the full training dataset\n",
        "df_train = pd.read_csv(data_dir / \"train.csv\")\n",
        "print(f\"Training set size: {len(df_train)}\")\n",
        "print(f\"Dataset columns: {list(df_train.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NPtKwB721zqk"
      },
      "outputs": [],
      "source": [
        "class FetalHealthPredictor:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the predictor for modified Fetal Health multi-class classification.\"\"\"\n",
        "        self.target_col = \"target\"\n",
        "\n",
        "        # Columns explicitly NOT allowed for training/testing\n",
        "        self.excluded_columns = {\n",
        "            \"date\",\n",
        "            \"heart_rate_status\",\n",
        "            \"fetal_age_in_days\",\n",
        "            \"blood_group\",\n",
        "            \"placenta_grade\",\n",
        "            \"amniotic_fluid\",\n",
        "            \"fetal_size\",\n",
        "            \"maternal_stress_index\",\n",
        "        }\n",
        "\n",
        "        self.feature_columns = None\n",
        "\n",
        "        self.preprocessor = Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler())\n",
        "        ])\n",
        "\n",
        "        # Gradient Boosting (tuned) for strong multi-class performance\n",
        "        self.model = HistGradientBoostingClassifier(\n",
        "            loss=\"log_loss\",\n",
        "            learning_rate=0.05,\n",
        "            max_iter=900,\n",
        "            max_depth=8,\n",
        "            min_samples_leaf=12,\n",
        "            l2_regularization=0.0,\n",
        "            max_bins=255,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.classes_ = np.array([1.0, 2.0, 3.0], dtype=float)\n",
        "\n",
        "    def _infer_feature_columns(self, df):\n",
        "        \"\"\"Infer usable feature columns by excluding target + banned columns.\"\"\"\n",
        "        cols = [c for c in df.columns if c != self.target_col and c not in self.excluded_columns]\n",
        "        return cols\n",
        "\n",
        "    def _align_features(self, df):\n",
        "        \"\"\"Align dataframe to expected feature schema, order and numeric dtype.\"\"\"\n",
        "        X = df.copy()\n",
        "\n",
        "        if self.feature_columns is None:\n",
        "            self.feature_columns = self._infer_feature_columns(X)\n",
        "\n",
        "        # Add missing columns\n",
        "        for col in self.feature_columns:\n",
        "            if col not in X.columns:\n",
        "                X[col] = 0.0\n",
        "\n",
        "        # Keep only expected columns in correct order\n",
        "        X = X[self.feature_columns]\n",
        "\n",
        "        # Coerce to numeric (invalid -> NaN)\n",
        "        X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "        return X\n",
        "\n",
        "    def fit(self, train_df):\n",
        "        \"\"\"Fits the model using train_df (must include the 'target' column).\"\"\"\n",
        "        if self.target_col not in train_df.columns:\n",
        "            raise ValueError(\"Training dataframe must include 'target' column\")\n",
        "\n",
        "        # Determine feature set from training data\n",
        "        self.feature_columns = self._infer_feature_columns(train_df)\n",
        "\n",
        "        X = self._align_features(train_df.drop(self.target_col, axis=1))\n",
        "        y = train_df[self.target_col].astype(int).values\n",
        "\n",
        "        Xp = self.preprocessor.fit_transform(X)\n",
        "        self.model.fit(Xp, y)\n",
        "\n",
        "        if hasattr(self.model, \"classes_\"):\n",
        "            self.classes_ = self.model.classes_.astype(float)\n",
        "\n",
        "        print(\"Training complete.\")\n",
        "\n",
        "    def predict_proba(self, df):\n",
        "        \"\"\"Returns class probabilities (n_samples, 3).\"\"\"\n",
        "        X = self._align_features(df)\n",
        "        Xp = self.preprocessor.transform(X)\n",
        "        proba = self.model.predict_proba(Xp)\n",
        "\n",
        "        # Ensure shape always (n, 3)\n",
        "        if proba.shape[1] != 3:\n",
        "            full = np.zeros((proba.shape[0], 3), dtype=float)\n",
        "            for j, cls in enumerate(self.classes_):\n",
        "                cls_int = int(float(cls))\n",
        "                if cls_int in (1, 2, 3):\n",
        "                    full[:, cls_int - 1] = proba[:, j]\n",
        "            row_sums = full.sum(axis=1, keepdims=True)\n",
        "            row_sums[row_sums == 0] = 1.0\n",
        "            full = full / row_sums\n",
        "            return full\n",
        "\n",
        "        return proba.astype(float)\n",
        "\n",
        "    def predict(self, df):\n",
        "        \"\"\"Returns class labels (1.0, 2.0, 3.0).\"\"\"\n",
        "        proba = self.predict_proba(df)\n",
        "        preds = np.argmax(proba, axis=1) + 1\n",
        "        return preds.astype(float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rgexGYBAx77"
      },
      "outputs": [],
      "source": [
        "# --- TRAINING ---\n",
        "\n",
        "predictor = FetalHealthPredictor()\n",
        "predictor.fit(df_train)\n",
        "\n",
        "print(\"Model training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Z9hDTestEval"
      },
      "outputs": [],
      "source": [
        "# --- TEST ON HIDDEN TEST DATASET (if available locally) ---\n",
        "\n",
        "test_data_path = Path(\"../tests/test.csv\")\n",
        "\n",
        "if test_data_path.exists():\n",
        "    df_test = pd.read_csv(test_data_path)\n",
        "    print(f\"Test set size: {len(df_test)}\")\n",
        "\n",
        "    y_true_test = df_test[\"target\"].astype(float)\n",
        "    df_test_features = df_test.drop(\"target\", axis=1)\n",
        "\n",
        "    y_pred_test = predictor.predict(df_test_features)\n",
        "    y_proba_test = predictor.predict_proba(df_test_features)\n",
        "\n",
        "    test_accuracy = metrics.accuracy_score(y_true_test, y_pred_test)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"HIDDEN TEST SET EVALUATION RESULTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "else:\n",
        "    print(f\"Test file not found at {test_data_path}\")\n",
        "    print(\"Skipping test evaluation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "make_results_dir"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /workspace/results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "write_utils"
      },
      "outputs": [],
      "source": [
        "utils_content = '''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "class FetalHealthPredictor:\n",
        "    def __init__(self):\n",
        "        self.target_col = \"target\"\n",
        "\n",
        "        self.excluded_columns = {\n",
        "            \"date\",\n",
        "            \"heart_rate_status\",\n",
        "            \"fetal_age_in_days\",\n",
        "            \"blood_group\",\n",
        "            \"placenta_grade\",\n",
        "            \"amniotic_fluid\",\n",
        "            \"fetal_size\",\n",
        "            \"maternal_stress_index\",\n",
        "        }\n",
        "\n",
        "        self.feature_columns = None\n",
        "\n",
        "        self.preprocessor = Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler())\n",
        "        ])\n",
        "\n",
        "        self.model = HistGradientBoostingClassifier(\n",
        "            loss=\"log_loss\",\n",
        "            learning_rate=0.05,\n",
        "            max_iter=900,\n",
        "            max_depth=8,\n",
        "            min_samples_leaf=12,\n",
        "            l2_regularization=0.0,\n",
        "            max_bins=255,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.classes_ = np.array([1.0, 2.0, 3.0], dtype=float)\n",
        "\n",
        "    def _infer_feature_columns(self, df):\n",
        "        cols = [c for c in df.columns if c != self.target_col and c not in self.excluded_columns]\n",
        "        return cols\n",
        "\n",
        "    def _align_features(self, df):\n",
        "        X = df.copy()\n",
        "\n",
        "        if self.feature_columns is None:\n",
        "            self.feature_columns = self._infer_feature_columns(X)\n",
        "\n",
        "        for col in self.feature_columns:\n",
        "            if col not in X.columns:\n",
        "                X[col] = 0.0\n",
        "\n",
        "        X = X[self.feature_columns]\n",
        "        X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
        "        return X\n",
        "\n",
        "    def fit(self, train_df):\n",
        "        if self.target_col not in train_df.columns:\n",
        "            raise ValueError(\"Training dataframe must include 'target' column\")\n",
        "\n",
        "        self.feature_columns = self._infer_feature_columns(train_df)\n",
        "\n",
        "        X = self._align_features(train_df.drop(self.target_col, axis=1))\n",
        "        y = train_df[self.target_col].astype(int).values\n",
        "\n",
        "        Xp = self.preprocessor.fit_transform(X)\n",
        "        self.model.fit(Xp, y)\n",
        "\n",
        "        if hasattr(self.model, \"classes_\"):\n",
        "            self.classes_ = self.model.classes_.astype(float)\n",
        "\n",
        "    def predict_proba(self, df):\n",
        "        X = self._align_features(df)\n",
        "        Xp = self.preprocessor.transform(X)\n",
        "        proba = self.model.predict_proba(Xp)\n",
        "\n",
        "        if proba.shape[1] != 3:\n",
        "            full = np.zeros((proba.shape[0], 3), dtype=float)\n",
        "            for j, cls in enumerate(self.classes_):\n",
        "                cls_int = int(float(cls))\n",
        "                if cls_int in (1, 2, 3):\n",
        "                    full[:, cls_int - 1] = proba[:, j]\n",
        "            row_sums = full.sum(axis=1, keepdims=True)\n",
        "            row_sums[row_sums == 0] = 1.0\n",
        "            full = full / row_sums\n",
        "            return full\n",
        "\n",
        "        return proba.astype(float)\n",
        "\n",
        "    def predict(self, df):\n",
        "        proba = self.predict_proba(df)\n",
        "        preds = np.argmax(proba, axis=1) + 1\n",
        "        return preds.astype(float)\n",
        "'''\n",
        "\n",
        "with open(\"/workspace/results/utils.py\", \"w\") as f:\n",
        "    f.write(utils_content)\n",
        "\n",
        "print(\"Wrote FetalHealthPredictor definition to /workspace/results/utils.py\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "nbformat": 4,
    "nbformat_minor": 0
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
